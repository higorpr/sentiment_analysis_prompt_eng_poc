{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import openai\n",
    "\n",
    "from connection import openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ef75e9235d9a3cae54c1973\n"
     ]
    }
   ],
   "source": [
    "# chat_id = input('Please enter the chat ID: ')\n",
    "chat_id = \"5ef75e9235d9a3cae54c1973\"\n",
    "print(f\"Analisando chat: {chat_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve messages:\n",
    "messages = functions.get_chat_messages(chat_id)\n",
    "\n",
    "\n",
    "# Create messages dataframe:w\n",
    "messages_df = functions.import_data(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages in chat:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of messages in chat:\")\n",
    "messages_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def split_dataframe(df: pd.DataFrame, n_parts: int) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split a chat dataframe into n parts.\n",
    "    \"\"\"\n",
    "    dataframe_dict = defaultdict()\n",
    "    n_rows = len(df)\n",
    "    n_rows_per_part = n_rows // n_parts\n",
    "    n_rows_leftover = n_rows % n_parts\n",
    "    start = 0\n",
    "    end = n_rows_per_part\n",
    "    for i in range(n_parts):\n",
    "        if i == n_parts - 1:\n",
    "            end += n_rows_leftover\n",
    "        dataframe_dict[i] = df.iloc[start:end]\n",
    "        start = end\n",
    "        end += n_rows_per_part\n",
    "    return dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def generate_gpt_message_input(\n",
    "    messages_df: pd.DataFrame, input_type: str = \"full\"\n",
    ") -> List[Dict]:\n",
    "    \"\"\" \"\"\"\n",
    "    initial_prompt = 'Eu vou fornecer uma conversa entre um cliente(C) e um atendente(A) e você deve me retornar o sentimento do cliente em,\\\n",
    " no máximo 2 palavras. Por exemplo: \"Muito Satisfeito\" ou \" Insatisfeito\".\\n \\\n",
    "\\nOs sentimentos possíveis do cliente, e consequentemente as opções de classificação de sentimento, são: \"Muito Satisfeito\", \"Satisfeito\", \"Neutro\", \"Insatisfeito\", \"Muito Insatisfeito\".'\n",
    "    single_message = \"\"\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"{initial_prompt}\"})\n",
    "\n",
    "    if input_type == \"client\":\n",
    "        single_message = functions.format_client_messages_to_gpt(messages_df)[\"string\"]\n",
    "        messages.append({\"role\": \"user\", \"content\": single_message})\n",
    "    if input_type == \"full\":\n",
    "        single_message = functions.format_chat_to_gpt(messages_df)[\"string\"]\n",
    "        messages.append({\"role\": \"user\", \"content\": single_message})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_chat_gpt_sentiment(gpt_formatted_messages):\n",
    "    \"\"\"\n",
    "    Get sentiment of a single chat using GPT-3\n",
    "    \"\"\"\n",
    "    # Get sentiment of the chat\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=gpt_formatted_messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_split(msg_df: pd.DataFrame):\n",
    "    # Formata o chat para o formato de entrada da OpenAI API\n",
    "    initial_input_messages = generate_gpt_message_input(msg_df)\n",
    "\n",
    "    # Calcula o número de tokens do chat\n",
    "    n_tokens = functions.num_tokens_from_messages(initial_input_messages)\n",
    "\n",
    "    # Divisão da dataframe baseado nos tokens\n",
    "    chat_parts = 1\n",
    "\n",
    "    dataframe_dict = split_dataframe(msg_df, chat_parts)\n",
    "\n",
    "    # Find minimum division of dataframe for number of tokens smaller than 3k\n",
    "    while n_tokens > 3000:\n",
    "        major_n_tokens = 0\n",
    "        dataframe_dict = split_dataframe(msg_df, chat_parts)\n",
    "\n",
    "        # Get dataframe with biggest token number and update n_tokens\n",
    "        for key, df in dataframe_dict.items():\n",
    "            gpt_input_messages = generate_gpt_message_input(df)\n",
    "            n_tokens_local = functions.num_tokens_from_messages(gpt_input_messages)\n",
    "            if n_tokens_local > major_n_tokens:\n",
    "                major_n_tokens = n_tokens_local\n",
    "                n_tokens = n_tokens_local\n",
    "\n",
    "        chat_parts += 1\n",
    "\n",
    "    return dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_to_score(sentiment: str):\n",
    "    score = 0\n",
    "\n",
    "    if sentiment == \"Satisfeito\":\n",
    "        score = 1\n",
    "    elif sentiment == \"Muito Satisfeito\":\n",
    "        score = 2\n",
    "    elif sentiment == \"Neutro\":\n",
    "        score = 0\n",
    "    elif sentiment == \"Muito Insatisfeito\":\n",
    "        score = -2\n",
    "    elif sentiment == \"Insatisfeito\":\n",
    "        score = -1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_gpt_sentiment(messages_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get the sentiment of a chat in the format of a list of GPT3 messages.\n",
    "\n",
    "    Input:\n",
    "        messages_df: Pandas DataFrame, the chat history.\n",
    "\n",
    "    Output:\n",
    "        sentiment_output: Dictionay containing \"average\" \n",
    "        (average sentiment scores of all chat parts) and \"sentiment_dict\"\n",
    "        (dictonary of scores of each chat part).\n",
    "    \"\"\"\n",
    "\n",
    "    sentiment = 0\n",
    "    sentiments = defaultdict(lambda: None)\n",
    "\n",
    "    chat_parts = get_chat_split(messages_df)\n",
    "    print(f\"The chat was divided into {len(chat_parts)} part(s)\")\n",
    "    for order, chat_df in chat_parts.items():\n",
    "        gpt_formatted_messages = generate_gpt_message_input(chat_df)\n",
    "        str_sentiment = get_single_chat_gpt_sentiment(gpt_formatted_messages)\n",
    "        partial_sentiment = sentiment_to_score(str_sentiment)\n",
    "        sentiment += partial_sentiment\n",
    "        sentiments[order] = partial_sentiment\n",
    "\n",
    "    sentiment /= len(chat_parts)\n",
    "\n",
    "    sentiment_output = {\"average\": sentiment, \"sentiment_dict\": sentiments}\n",
    "\n",
    "    return sentiment_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chat was divided into 5 part(s)\n"
     ]
    }
   ],
   "source": [
    "gpt_return = get_gpt_sentiment(messages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average': 1.4,\n",
       " 'sentiment_dict': defaultdict(None, {0: 2, 1: 1, 2: 1, 3: 1, 4: 2})}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
